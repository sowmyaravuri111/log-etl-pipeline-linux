# ğŸ›  Log ETL Pipeline using Linux + PostgreSQL

A lightweight Linux-based ETL (Extract, Transform, Load) pipeline project designed for Data Engineering practice. It filters web server logs and loads cleaned data into a PostgreSQL database.

---

## ğŸ“ Project Structure

log-etl-pipeline-linux/ â”œâ”€â”€ rawlogs/ # Contains raw access log file â”œâ”€â”€ data/ # Cleaned logs & backup.sql â”œâ”€â”€ scripts/ # Bash & Python scripts for ETL â”œâ”€â”€ test_read_log.py # Simple log reader script â”œâ”€â”€ requirements.txt # Python dependencies â””â”€â”€ README.md # Project overview

yaml
Copy
Edit

---

## ğŸš€ What It Does

- âœ… **Extracts**: Reads raw web server logs  
- ğŸ§¹ **Transforms**: Filters only `200 OK` responses and removes bots  
- ğŸ’¾ **Loads**: Inserts cleaned data into a PostgreSQL table (`web_logs`)  
- ğŸ˜ Uses **PostgreSQL** instead of SQLite  

---

## ğŸ”§ How to Run

### 1. Prepare Logs

```bash
cat scripts/access_temp.log | grep " 200 " | grep -viE 'bot|c' > data/cleaned_log.log
2. Run the Python ETL Script
bash
Copy
Edit
python scripts/etl_to_postgres.py
â¡ï¸ Make sure PostgreSQL is running and a table web_logs exists in the log_db database.

ğŸ“¦ Requirements
Python 3.x

PostgreSQL

Python libraries:
psycopg2

Install them with:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ›¡ .gitignore
bash
Copy
Edit
data/logs.db
*.pyc
__pycache__/
access_temp.log
cleaned_logs/
ğŸ“„ License
MIT License

Built with â¤ï¸ by Sowmya Ravuri

yaml
Copy
Edit




